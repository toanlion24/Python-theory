{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Basics Theory Quiz - 40 Hard Questions (Questions Only)\n\n**Advanced Theory Quiz** - Deep Understanding Required\n\nThis quiz contains 40 difficult theoretical questions covering Python basics, designed to test deep understanding of Python concepts, internals, and subtle behaviors.\n\n**Instructions:**\n- Each question has 5 answer options (A, B, C, D, E)\n- Only one answer is correct\n- Questions are theory-based (no code execution required)\n- Questions cover: Syntax, Variables, Data Types, Strings, Conditionals, Loops, Typecasting, Exceptions, Functions, Lists, Tuples, Sets, Dictionaries\n- All questions and answers are in English\n- Answer options are highly distracting with plausible incorrect choices\n\n**Difficulty Level:** Hard - Requires deep understanding of Python internals and edge cases\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Default Argument Evaluation\n\n**Theory:** Python evaluates default arguments only once when the function is defined, not each time the function is called. For mutable objects like lists or dictionaries, this creates a shared object across all function calls.\n\nWhy does this behavior occur, and what is the fundamental reason Python was designed this way?\n\nA) Python is trying to optimize memory usage by reusing objects, and default arguments are treated as class variables that persist across calls\n\nB) Default arguments are evaluated during function definition, not during function call, which is more efficient but creates shared mutable state when mutable objects are used\n\nC) Python treats default arguments as global variables that are created once when the module is loaded, making them accessible to all function instances\n\nD) This is a bug in Python's implementation that should be fixed; default arguments should be evaluated fresh each time to prevent this unexpected behavior\n\nE) Default arguments are stored as constants in the function's bytecode, and Python reuses constant objects to save memory, which only affects immutable types\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Mutable vs Immutable Types\n\n**Theory:** In Python, some types are mutable (can be changed in-place) while others are immutable (cannot be changed once created). Understanding this distinction is crucial for understanding Python's behavior.\n\nWhich statement accurately describes Python's memory management for mutable vs immutable objects?\n\nA) Immutable objects are always stored on the stack, while mutable objects are stored on the heap, which explains why strings cannot be modified but lists can\n\nB) All objects in Python are actually mutable; the difference is that \"immutable\" types have methods that return new objects instead of modifying in-place, creating an illusion of immutability\n\nC) Immutable objects can be cached and reused (interning), and their identity can be shared, while mutable objects must have unique identities to prevent unintended sharing of modified state\n\nD) Python uses copy-on-write for immutable objects, meaning they appear immutable but are actually modified internally; only when you explicitly create a new object does Python allocate new memory\n\nE) The mutable/immutable distinction is purely a convention for developers; Python treats all objects the same internally, and the distinction only affects which methods are available\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: String Interning\n\n**Theory:** Python may intern certain strings, storing them in a special internal cache and reusing the same object for multiple string literals with the same value.\n\nUnder what conditions does Python reliably intern strings, and why might two strings with identical content not have the same identity?\n\nA) Python interns all strings automatically to save memory, but only for strings shorter than 20 characters; longer strings are never interned regardless of how they're created\n\nB) Python automatically interns all string literals in source code during compilation, but strings created dynamically at runtime (like through concatenation or input) are not interned, even if they match an interned literal\n\nC) String interning only occurs for strings that appear more than 3 times in the same module; this optimization was added in Python 3.8 to reduce memory for frequently used strings\n\nD) All strings in Python are interned if they contain only ASCII characters; non-ASCII characters prevent interning due to encoding complexities, which is why Unicode strings use more memory\n\nE) String interning is never guaranteed in Python; it's an implementation detail that varies between Python versions and should never be relied upon, making `is` comparisons unreliable for strings\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: List vs Tuple Performance\n\n**Theory:** Lists and tuples are both sequence types in Python, but lists are mutable while tuples are immutable. This difference affects both functionality and performance.\n\nIn terms of memory usage and performance, which statement is most accurate about when to use tuples vs lists?\n\nA) Tuples use significantly less memory than lists because they are stored as fixed-size arrays, while lists require extra space for growth; tuples should always be preferred for read-only sequences\n\nB) The memory difference between tuples and lists is minimal; tuples are slightly faster for iteration but lists are faster for random access, so the choice should be based on mutability needs rather than performance\n\nC) Lists are more memory-efficient than tuples because they use dynamic allocation, while tuples allocate fixed-size blocks that may waste space; lists should be preferred unless immutability is required\n\nD) Tuples consume exactly half the memory of lists because they don't store metadata about mutability; this makes tuples the preferred choice for large collections of homogeneous data\n\nE) The memory overhead is identical; tuples are just lists with a flag set to prevent modification, so there's no performance benefit to using tuples over lists\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Dictionary Key Requirements\n\n**Theory:** Dictionary keys must be hashable, which means they must be immutable types that implement both __hash__() and __eq__() methods consistently.\n\nWhy must dictionary keys be hashable, and what would happen if mutable types like lists were allowed as keys?\n\nA) Hashable keys are required for the dictionary's hash table implementation; if lists were keys, changing a list after it's used as a key would break the hash table's lookup mechanism because the hash value would change but the key in the table wouldn't be updated\n\nB) Dictionary keys don't actually need to be hashable; this restriction exists only to prevent beginner mistakes, and in future Python versions, all types will be allowed as keys\n\nC) The hashable requirement is for security reasons; allowing mutable keys would create vulnerabilities where attackers could modify keys to access unauthorized dictionary entries\n\nD) Hashable keys enable faster lookups using hash codes; mutable keys are allowed in some programming languages, but Python's restriction is arbitrary and could be removed without issues\n\nE) Keys must be hashable so dictionaries can be serialized to JSON; if lists were keys, JSON serialization would fail because JSON objects require string keys\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: Scope Resolution (LEGB Rule)\n\n**Theory:** Python follows the LEGB rule for name resolution: Local, Enclosing (nonlocal), Global, and Built-in scopes are searched in that order.\n\nWhat happens when you assign a value to a variable inside a function if a variable with the same name exists in the global scope?\n\nA) The assignment automatically modifies the global variable; Python always searches global scope first when assigning, so no special keyword is needed to modify globals\n\nB) The assignment creates a new local variable that shadows the global variable; to modify the global variable, you must use the `global` keyword before the assignment\n\nC) Python raises a SyntaxError because you cannot have local and global variables with the same name; you must rename one to avoid the conflict\n\nD) The assignment modifies the global variable if it's mutable (like a list), but creates a local variable if it's immutable (like a string); this behavior depends on the type\n\nE) Python uses the value from the nearest scope (local first), but assignment always modifies the global scope regardless of where the assignment occurs\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7: Exception Handling and Finally Block\n\n**Theory:** The `finally` block in Python always executes, whether an exception occurs or not, and even if there's a return statement in the try or except block.\n\nWhat is the order of execution when a `finally` block contains a return statement, and how does it interact with return statements in try/except blocks?\n\nA) The finally block executes after try/except, and if finally has a return statement, it completely overrides any return value from try/except blocks, making the earlier return value inaccessible\n\nB) The finally block executes, but any return statement in finally is ignored; only the return from try/except blocks matters, and finally just executes cleanup code without affecting return values\n\nC) If finally has a return, it executes first before try/except returns, allowing finally to modify the return value by passing it through additional processing before the function actually returns\n\nD) Finally blocks with return statements are illegal in Python and raise a SyntaxError; the finally block can only contain cleanup code, not control flow statements like return\n\nE) The order depends on the Python version: Python 2 executes finally after return, while Python 3 changed this to execute finally before return, preserving both return values\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8: Generator Expressions vs List Comprehensions\n\n**Theory:** Generator expressions use parentheses and create iterator objects that yield values on-demand, while list comprehensions create complete lists in memory immediately.\n\nWhat are the key memory and performance differences between generator expressions and list comprehensions?\n\nA) Generator expressions use exactly the same amount of memory as list comprehensions because both are evaluated lazily in Python 3; the only difference is syntax preference\n\nB) List comprehensions are faster for small datasets but generators are faster for large datasets; however, both consume the same memory, with generators just deferring allocation\n\nC) Generator expressions are memory-efficient because they produce values one at a time on-demand, while list comprehensions create the entire list in memory immediately; generators are iterators that don't store all values\n\nD) Generators consume more memory because they must store the entire computation state, while list comprehensions just store values; lists are more efficient for memory but slower to create\n\nE) The difference is purely conceptual; Python's interpreter converts generator expressions to list comprehensions internally, so there's no actual performance or memory difference\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9: Shallow Copy vs Deep Copy\n\n**Theory:** Shallow copy creates a new object but doesn't recursively copy nested objects, so nested mutable objects are still shared. Deep copy recursively copies all nested objects.\n\nWhen does a shallow copy behave differently from a deep copy, and what is the underlying mechanism that causes this difference?\n\nA) Shallow and deep copies always behave identically; the distinction is only relevant in other programming languages, and Python's copy module treats them the same way\n\nB) Shallow copies only differ from deep copies for tuples containing lists; for all other data structures, both copy types produce identical results because Python optimizes copying\n\nC) Shallow copy creates a new container object but references to nested objects point to the same memory locations; deep copy recursively creates new objects for all nested structures, preventing shared references\n\nD) Shallow copy is faster but only works for flat structures; deep copy is slower but required for nested structures; Python automatically chooses the appropriate method based on data structure depth\n\nE) The difference is in how immutable types are handled: shallow copy reuses immutable nested objects (saving memory), while deep copy unnecessarily duplicates immutable objects, wasting memory\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10: Set Uniqueness and Hashing\n\n**Theory:** Sets in Python automatically maintain uniqueness by using hash values to quickly identify and prevent duplicate elements.\n\nHow does Python ensure set elements are unique, and what happens when you try to add a duplicate element?\n\nA) Sets maintain a sorted list internally and check for duplicates by comparing each new element with all existing elements; adding duplicates raises a ValueError\n\nB) Sets use hash values for quick lookup; when adding an element, Python computes its hash, checks if that hash exists, and if the element equals an existing element with the same hash, it silently ignores the duplicate\n\nC) Sets check for duplicates using the `==` operator against all existing elements in order; this O(n) check makes sets slow for large collections but ensures perfect uniqueness\n\nD) Uniqueness is enforced by converting all elements to strings and comparing their string representations; this means [1,2] and \"[1,2]\" would be considered duplicates\n\nE) Sets don't actually enforce uniqueness; duplicates are stored but filtered during iteration, which is why len(set) may not equal the number of elements added\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11: List Comprehension vs Loop Performance\n\n**Theory:** List comprehensions are generally faster than equivalent for loops for creating lists, but the reasons for this performance difference are often misunderstood.\n\nWhy are list comprehensions typically faster than equivalent for loops for creating lists?\n\nA) List comprehensions are compiled to optimized bytecode that avoids the overhead of the loop variable and append method calls, executing operations more efficiently in the Python virtual machine\n\nB) List comprehensions are faster because they use C extensions under the hood, while for loops execute entirely in Python bytecode, making comprehensions nearly as fast as C code\n\nC) The performance difference is a myth; list comprehensions are actually slower because they create a temporary list internally before returning, while loops can modify lists in-place more efficiently\n\nD) List comprehensions automatically parallelize across multiple CPU cores, while loops run sequentially; this parallelization provides the speed advantage for large datasets\n\nE) The speed comes from list comprehensions being interpreted as generator expressions first, then converted to lists; this two-step process is more optimized than single-step loops\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12: Type Coercion in Operations\n\n**Theory:** Python automatically converts between compatible numeric types during operations (like int + float), but this behavior has specific rules.\n\nHow does Python handle type coercion when performing operations between different numeric types?\n\nA) Python never converts types automatically; operations between different types always raise TypeError; you must explicitly convert types using int(), float(), or str() before operations\n\nB) Python follows a hierarchy: complex > float > int; when mixing types, Python automatically converts to the \"higher\" type in this hierarchy to preserve precision and avoid information loss\n\nC) Type coercion depends on the operation: addition converts to float, multiplication converts to int, and division always produces float regardless of input types\n\nD) Python uses the type of the first operand; if the first operand is int, the result is int; if it's float, the result is float; types are never mixed in calculations\n\nE) All numeric operations return strings to ensure type safety; numbers are converted to strings before operations, then parsed back, which prevents type-related errors\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 13: String Slicing Behavior\n\n**Theory:** String slicing in Python uses indices and creates new string objects; understanding how negative indices and step values work is crucial.\n\nWhat happens when you slice a string with a step value of -1, and how does Python handle the start and stop indices in this case?\n\nA) A step of -1 reverses the string, but only if start is 0 and stop is omitted; if start and stop are specified, Python raises ValueError because negative steps require special handling\n\nB) A step of -1 reverses the string; start and stop still work normally but are interpreted relative to the original string (not the reversed one), so [::-1] reverses the entire string\n\nC) Negative step values are not supported for strings; only lists can be sliced with negative steps; strings require using reversed() function instead\n\nD) When step is -1, start must be greater than stop for the slice to work; Python automatically swaps them if start < stop, which is why [::-1] works for reversing\n\nE) Negative steps only work with lists, not strings; string slicing with step=-1 creates a list of characters, not a reversed string, requiring join() to reconstruct the string\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 14: Dictionary View Objects\n\n**Theory:** Dictionary methods like .keys(), .values(), and .items() return view objects that reflect changes to the dictionary in real-time.\n\nWhat are dictionary view objects, and how do they differ from returning lists of keys/values/items?\n\nA) View objects are just lists that are updated whenever the dictionary changes; Python maintains a hidden link between the dictionary and these list views, keeping them synchronized automatically\n\nB) View objects are dynamic proxies that provide a live, read-only window into the dictionary's current state; they reflect changes immediately and are memory-efficient because they don't store copies\n\nC) Views are deprecated in Python 3; they were replaced with lists because views caused performance issues when dictionaries were modified during iteration\n\nD) View objects are identical to lists in every way; Python uses the term 'view' for backward compatibility with Python 2, but they're actually standard list objects under the hood\n\nE) Views only work for .items(); .keys() and .values() return lists because only item views need to track changes; keys and values are simple enough to return as lists\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 15: Loop Else Clause\n\n**Theory:** Python's for and while loops can have an else clause that executes when the loop completes normally (without a break statement).\n\nWhen does the else clause of a loop execute, and what is its primary use case?\n\nA) The else clause always executes after the loop completes, regardless of whether break was used; it's equivalent to putting code after the loop, making it redundant syntax\n\nB) The else clause executes when the loop completes normally without encountering a break statement; it's useful for code that should run when a search or iteration completes without finding a match\n\nC) Else clauses in loops are a syntax error in Python; only if statements can have else clauses; this feature doesn't actually exist and would cause SyntaxError\n\nD) Else executes only if the loop body never executes (empty iteration); if the loop runs at least once, else is skipped, making it useful for handling empty sequences\n\nE) Else in loops works like try/except: it catches LoopBreakException when break is called, allowing cleanup code; without break, the exception never occurs so else runs normally\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 16: Argument Unpacking (*args, **kwargs)\n\n**Theory:** *args collects positional arguments into a tuple, while **kwargs collects keyword arguments into a dictionary.\n\nWhat happens when you define a function with both *args and **kwargs, and in what order must they appear?\n\nA) *args and **kwargs can appear in any order; Python automatically sorts them by type, placing positional collectors before keyword collectors regardless of declaration order\n\nB) *args must come before **kwargs because *args collects remaining positional arguments and **kwargs collects remaining keyword arguments; this order is required by Python's syntax\n\nC) You cannot use both *args and **kwargs in the same function; Python raises SyntaxError because having both creates ambiguity about which arguments go where\n\nD) *args and **kwargs are interchangeable; both collect all remaining arguments into a dictionary, with *args being a legacy syntax that's equivalent to **kwargs in modern Python\n\nE) The order doesn't matter for definition, but when calling the function, you must pass *args before **kwargs, or Python will raise TypeError about argument order\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 17: Boolean Evaluation (Truthy/Falsy)\n\n**Theory:** Python evaluates values as truthy or falsy in boolean contexts; empty collections, zero, None, and False are falsy.\n\nWhat determines whether a value is considered truthy or falsy in Python, and can you override this behavior?\n\nA) All values are truthy except the literal False; None, 0, and empty collections are actually truthy, but Python's if statements have special handling that treats them as falsy for convenience\n\nB) Python uses the __bool__() method (or __len__() if __bool__() is absent) to determine truthiness; classes can override these methods to customize boolean evaluation\n\nC) Truthiness is hardcoded in Python's interpreter and cannot be changed; only the built-in types have defined truthiness, and custom classes always evaluate to True\n\nD) Python checks if a value equals False, None, 0, or empty collections using == comparison; custom classes can override __eq__() to change their truthiness\n\nE) Truthiness depends on the value's memory address: odd addresses are truthy, even addresses are falsy; this low-level behavior cannot be overridden by user code\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 18: List Methods Return Values\n\n**Theory:** Some list methods like append() and sort() modify the list in-place and return None, while others like pop() return values.\n\nWhy do methods like append() and sort() return None instead of returning the modified list?\n\nA) They return None to prevent method chaining, which Python's designers consider bad style; if they returned self, developers might write confusing chains like list.append(1).append(2)\n\nB) Returning None indicates the operation modifies the object in-place; if methods returned the list, it would create confusion about whether a new list is created or the existing one is modified\n\nC) This is a bug in Python's design; these methods should return self to enable method chaining like in other languages, and this inconsistency will be fixed in Python 4.0\n\nD) Methods return None when they fail; if the operation succeeds, they return the modified list; checking the return value tells you if the operation worked\n\nE) Only methods that don't modify the list (like copy()) return values; methods that modify in-place return None as a signal that no new object is created, saving memory\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 19: Import Statement Behavior\n\n**Theory:** Python's import statement loads modules and makes their contents available in the current namespace.\n\nWhat happens when you import the same module multiple times, and how does Python handle module caching?\n\nA) Each import statement reloads the module from disk and executes its code again; multiple imports mean multiple executions, which is why you might see print statements in modules run multiple times\n\nB) Python caches imported modules in sys.modules; subsequent imports return the cached module object without re-executing the module's code, ensuring modules are only loaded once\n\nC) Import statements are processed at compile time; by the time Python runs, all imports have been resolved, so multiple import statements for the same module are optimized away completely\n\nD) Modules are imported separately each time, but Python uses file modification times to skip re-execution if the file hasn't changed since the last import, providing an optimization layer\n\nE) The behavior depends on how you import: 'import module' caches, but 'from module import' doesn't cache, so each 'from' import re-executes the module code\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 20: Set Operations Complexity\n\n**Theory:** Set operations like union, intersection, and membership testing are generally efficient due to hash-based implementation.\n\nWhat is the time complexity of checking if an element exists in a set, and why is this possible?\n\nA) O(n) linear time because sets must scan all elements to check for membership; this is why sets are slower than lists for membership testing in some cases\n\nB) O(1) average case because sets use hash tables; Python computes the element's hash, uses it to find the bucket, and checks if the element exists in that bucket, making lookup nearly instantaneous\n\nC) O(log n) logarithmic time because Python stores sets as balanced binary trees internally; the tree structure provides efficient searching but requires maintaining sorted order\n\nD) Complexity varies: O(1) for small sets but O(n) for large sets because hash collisions become more frequent as set size grows, degrading performance linearly\n\nE) Sets don't support membership testing efficiently; 'in' operations on sets actually convert the set to a list first, making them O(n) operations that are slower than list membership\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 21: Tuple Packing and Unpacking\n\n**Theory:** Tuples can be created without parentheses (tuple packing), and values can be assigned from tuples (tuple unpacking).\n\nWhat is tuple unpacking, and what special syntax does Python provide for handling variable numbers of values?\n\nA) Tuple unpacking only works with exactly matching numbers of variables and values; if counts don't match, Python raises ValueError, and there's no way to handle variable-length unpacking\n\nB) Python supports extended unpacking using * to capture multiple values; you can use patterns like 'first, *middle, last = sequence' to unpack sequences of any length into variables\n\nC) Unpacking is just syntactic sugar for indexing; 'a, b = (1, 2)' is identical to 'a = (1,2)[0]; b = (1,2)[1]', and the * syntax doesn't actually exist in Python\n\nD) The * operator in unpacking creates a list of the remaining values, but this only works with lists, not tuples; tuple unpacking requires exact matching of elements and variables\n\nE) Extended unpacking with * was removed in Python 3 because it caused confusion; you must now use slicing or indexing to extract multiple values from sequences\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 22: String Formatting Methods\n\n**Theory:** Python provides multiple string formatting methods: % formatting, .format(), and f-strings (formatted string literals).\n\nWhat are the key differences between f-strings and .format() method, and when should you use each?\n\nA) f-strings are evaluated at runtime and can contain expressions, while .format() is evaluated at compile time and only accepts variable names; f-strings are faster but less flexible\n\nB) f-strings are evaluated at compile time and are faster, allow embedding expressions directly in strings, and are generally preferred in Python 3.6+; .format() is older syntax but more flexible for dynamic formatting\n\nC) There's no difference; f-strings are just syntactic sugar that Python converts to .format() calls internally, so they're identical in performance and capability\n\nD) f-strings only work with variable names, not expressions, while .format() supports complex formatting operations; .format() is more powerful and should be used for anything beyond simple variable substitution\n\nE) f-strings don't actually exist; the f prefix was proposed but never implemented in Python; you must use .format() or % formatting for all string formatting needs\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 23: Exception Hierarchy\n\n**Theory:** Python has a hierarchy of exception classes; catching a parent exception also catches all child exceptions.\n\nWhat is Python's exception hierarchy, and why is the order of except clauses important?\n\nA) All exceptions are independent with no hierarchy; you can catch exceptions in any order, and Python will match the first except clause that has the exception type listed\n\nB) Exceptions form a hierarchy with BaseException at the top; except clauses are evaluated from first to last, so more specific exceptions should be caught before general ones (child before parent)\n\nC) The exception hierarchy only exists for built-in exceptions; custom exceptions don't participate in inheritance, so they can be caught in any order without issues\n\nD) Python doesn't check exception hierarchy when matching except clauses; it uses string matching on exception names, so order doesn't matter and any except clause can catch any exception\n\nE) Exception hierarchy is ignored during exception handling; Python always catches the most recent exception type first, regardless of class inheritance relationships\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 24: Identity vs Equality Operators\n\n**Theory:** Python has two comparison operators: 'is' checks identity (same object), '==' checks equality (same value).\n\nWhen should you use 'is' vs '==', and what are the implications of each?\n\nA) 'is' and '==' are interchangeable in most cases; 'is' is just a faster version of '==' that works for all types, so you should always use 'is' for better performance\n\nB) 'is' compares object identity (memory addresses) and should be used for None, True, False, and checking if two variables reference the same object; '==' compares values and should be used for value comparisons\n\nC) 'is' only works for primitive types like int and str; for complex types like lists and dicts, you must use '==', and 'is' will always return False even for identical objects\n\nD) 'is' is deprecated in Python 3 and will be removed; you should use '==' for all comparisons, and Python automatically optimizes '==' to check identity when appropriate\n\nE) There's no difference; Python's interpreter automatically converts 'is' to '==' for all comparisons, so both operators behave identically in all cases\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 25: Function Closure\n\n**Theory:** Python functions can capture variables from their enclosing scope, creating closures that maintain references to those variables.\n\nWhat is a closure, and how does Python handle variable references in nested functions?\n\nA) Closures don't exist in Python; nested functions can only access global variables, not variables from enclosing scopes, because Python doesn't support lexical scoping\n\nB) A closure is a function that captures variables from its enclosing scope; Python maintains references to these variables, allowing the inner function to access and modify outer scope variables even after the outer function returns\n\nC) Python creates copies of outer scope variables when creating closures; modifying these variables in inner functions doesn't affect the outer scope because closures work with value copies, not references\n\nD) Closures only work for immutable types like strings and numbers; mutable types like lists cannot be captured in closures because Python doesn't allow mutable closures for safety reasons\n\nE) Closures are a theoretical concept that isn't actually implemented in Python; the term is used in other languages but Python uses a different mechanism called 'scope inheritance'\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 26: Iterator Protocol\n\n**Theory:** Iterators are objects that implement __iter__() and __next__() methods, allowing iteration over collections.\n\nWhat is the iterator protocol, and how do for loops use iterators internally?\n\nA) Iterators don't exist in Python; for loops directly access list indices and use indexing to iterate, which is why loops only work with sequences that support indexing\n\nB) The iterator protocol requires __iter__() to return self and __next__() to return the next value or raise StopIteration; for loops automatically call these methods, converting iterables to iterators\n\nC) Iterators are only used for generator functions; regular for loops use a different mechanism called 'sequence protocol' that requires __getitem__() and __len__() methods\n\nD) The iterator protocol was removed in Python 3; modern for loops use a new 'iterable protocol' that only requires objects to be subscriptable (support indexing with []), not true iterators\n\nE) Iterators must implement __has_next__() and __get_next__() methods; __iter__() and __next__() are legacy Python 2 methods that are deprecated but still supported for compatibility\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 27: List Slicing Behavior\n\n**Theory:** List slicing creates new list objects; understanding how indices work with slicing is important for avoiding common mistakes.\n\nWhat happens when you assign to a list slice, and how does it differ from assigning to an index?\n\nA) Assigning to a slice replaces the slice with a single value, reducing the list length; assigning to an index replaces one element, keeping the length the same\n\nB) Slice assignment replaces the specified slice with the elements from the right-hand side, which can change the list length; index assignment replaces one element at that position\n\nC) Slice and index assignment are identical; both replace elements, and Python automatically converts slice assignment to index assignment internally\n\nD) Slice assignment doesn't work in Python; you can only assign to individual indices, and attempting slice assignment raises TypeError\n\nE) Assigning to a slice creates a new list and reassigns the variable, while index assignment modifies in-place; slices always create copies, never modify originals\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 28: Type Checking vs Duck Typing\n\n**Theory:** Python uses duck typing (behavior-based typing) rather than strict type checking; 'if it walks like a duck and quacks like a duck, it's a duck.'\n\nWhat is duck typing, and why does Python prefer it over explicit type checking?\n\nA) Duck typing means Python automatically converts types to match what's expected; if a function expects a string but gets an int, Python converts it automatically\n\nB) Duck typing means code works with any object that has the required methods/attributes, regardless of its actual type; this promotes flexibility and polymorphism without inheritance requirements\n\nC) Duck typing is a type system that requires all objects to explicitly declare what 'duck interface' they implement; it's stricter than regular typing because it enforces interface contracts\n\nD) Duck typing was removed in Python 3.5 with the introduction of type hints; modern Python requires explicit type declarations, making duck typing obsolete\n\nE) Duck typing means Python checks types at runtime and raises TypeError if types don't match; it's called 'duck' typing because it's as strict as a duck's quacking requirements\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 29: Dictionary Ordering (Python 3.7+)\n\n**Theory:** As of Python 3.7, dictionaries maintain insertion order as part of the language specification (it was implementation detail in 3.6).\n\nWhat does it mean that dictionaries maintain insertion order, and what are the implications?\n\nA) Dictionaries are automatically sorted by key values; when you iterate or print a dict, keys appear in sorted order regardless of insertion order\n\nB) Dictionaries preserve the order in which key-value pairs were added; iterating over a dictionary will return items in the same order they were inserted, which is guaranteed in Python 3.7+\n\nC) Insertion order only matters for display purposes; dict.keys(), .values(), and .items() return ordered results, but dictionary lookups still use hash-based ordering internally\n\nD) Order preservation is optional; dictionaries have an 'ordered=True' parameter when creating them, and if not specified, they revert to random ordering like Python 2\n\nE) This feature only works for string keys; dictionaries with non-string keys don't maintain order because hashing for non-strings produces unpredictable ordering\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 30: Lambda Functions Limitations\n\n**Theory:** Lambda functions are anonymous functions that can only contain expressions, not statements.\n\nWhat are the limitations of lambda functions compared to regular functions?\n\nA) Lambda functions are identical to regular functions; the 'lambda' keyword is just syntactic sugar, and there are no functional differences or limitations\n\nB) Lambdas can only contain a single expression (no statements like if/else blocks, loops, or assignments), cannot have docstrings or annotations, and are limited in complexity\n\nC) The only limitation is that lambdas cannot have default arguments; everything else (loops, conditionals, assignments) works identically to regular functions\n\nD) Lambda functions are slower than regular functions because they're interpreted rather than compiled; this is the main limitation, but syntax is identical\n\nE) Lambdas can only be used as function arguments (like in map/filter); they cannot be assigned to variables or used as standalone functions, which is their primary limitation\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 31: Built-in Functions: all() and any()\n\n**Theory:** all() returns True if all elements are truthy; any() returns True if any element is truthy.\n\nWhat do all() and any() return for empty iterables, and why?\n\nA) all([]) returns False and any([]) returns False because empty collections cannot contain truthy values, so both conditions fail\n\nB) all([]) returns True (vacuously true - no falsy elements exist) and any([]) returns False (no truthy elements exist); this follows mathematical logic for universal and existential quantifiers\n\nC) Both raise ValueError for empty iterables because the question 'are all/any elements truthy?' is undefined when there are no elements to check\n\nD) The return value depends on the type: all([]) is True for lists but False for sets, while any([]) is False for lists but True for sets, due to different empty type behaviors\n\nE) all() and any() don't work with empty iterables; you must check if the iterable is empty before calling these functions, or they'll raise EmptyIterableError\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 32: Multiple Inheritance and MRO\n\n**Theory:** Python supports multiple inheritance and uses Method Resolution Order (MRO) to determine which method to call when classes inherit from multiple parents.\n\nHow does Python's Method Resolution Order (MRO) work, and what algorithm does it use?\n\nA) Python uses depth-first search: it checks the first parent completely, then the second parent, so the order depends on how base classes are listed in the class definition\n\nB) Python uses C3 Linearization algorithm, which ensures a consistent order that respects the inheritance hierarchy and prevents ambiguous method resolution; it creates a linear ordering of classes\n\nC) MRO is random in Python; the interpreter picks an arbitrary but consistent order when the class is defined, which is why multiple inheritance should be avoided\n\nD) Python doesn't actually support multiple inheritance; the MRO algorithm is a theoretical concept, and Python raises TypeError when you try to inherit from multiple classes\n\nE) MRO uses alphabetical ordering of class names; Python sorts base classes alphabetically and searches in that order, making method resolution predictable but potentially unintuitive\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 33: Context Managers (with statement)\n\n**Theory:** Context managers provide a way to allocate and release resources using the 'with' statement, ensuring cleanup even if exceptions occur.\n\nHow do context managers work, and what methods must objects implement to be usable with 'with' statements?\n\nA) Context managers don't require any special methods; any object can be used with 'with', and Python automatically calls cleanup methods if they exist\n\nB) Objects must implement __enter__() (called when entering) and __exit__() (called when leaving, even if exceptions occur); these methods enable resource management with 'with'\n\nC) Only file objects support 'with' statements; other objects cannot be used as context managers because the 'with' statement is hardcoded to only work with files\n\nD) Context managers must implement __open__() and __close__() methods, which are automatically called; __enter__ and __exit__ are legacy names from Python 2\n\nE) The 'with' statement just calls __del__() when the block exits; any object with a destructor can be used with 'with', and no special methods are required\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 34: Dynamic Typing vs Static Typing\n\n**Theory:** Python is dynamically typed: variable types are determined at runtime, not declared in code.\n\nWhat are the advantages and disadvantages of Python's dynamic typing compared to static typing?\n\nA) Dynamic typing has no advantages; it's inherently worse than static typing because type errors are caught at runtime instead of compile time, making programs less reliable\n\nB) Dynamic typing provides flexibility and less boilerplate but catches type errors at runtime; static typing catches errors earlier but requires more explicit type declarations\n\nC) There's no difference; Python 3.5+ requires static type declarations using type hints, making Python statically typed, so the question is based on outdated information about Python 2\n\nD) Dynamic typing is faster because the interpreter doesn't need to check types; static typing languages are slower due to compile-time type checking overhead\n\nE) Dynamic typing means types can change during execution (a variable can be int then str); static typing prevents this, but Python allows both, so the distinction is meaningless\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 35: String Immutability Consequences\n\n**Theory:** Strings are immutable in Python; operations that appear to modify strings actually create new string objects.\n\nWhat are the performance implications of string immutability, especially for operations like concatenation in loops?\n\nA) String immutability improves performance because Python can reuse string objects safely; concatenation is faster than with mutable strings because no copying is needed\n\nB) Repeated string concatenation in loops is inefficient because each operation creates a new string object; using join() or list comprehensions is more efficient for building strings\n\nC) Immutability has no performance impact; Python's interpreter automatically optimizes string operations, making concatenation as fast as mutable string modification\n\nD) String immutability makes concatenation faster because Python uses a string pool to cache concatenation results; repeated concatenations reuse cached strings, improving speed\n\nE) The performance difference only matters for strings longer than 1000 characters; shorter strings are handled efficiently regardless of mutability due to Python's optimizations\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 36: Garbage Collection\n\n**Theory:** Python uses automatic garbage collection to reclaim memory from objects that are no longer referenced.\n\nHow does Python's garbage collector work, and when are objects deleted from memory?\n\nA) Python immediately deletes objects when they go out of scope; garbage collection happens synchronously, ensuring memory is freed as soon as variables are no longer accessible\n\nB) Python uses reference counting (immediate cleanup when count reaches 0) plus a cyclic garbage collector (handles circular references); objects are deleted when no longer referenced and GC runs\n\nC) Python doesn't have garbage collection; memory is managed manually using del statements, and objects persist until explicitly deleted, which is why Python programs can have memory leaks\n\nD) Garbage collection only runs when explicitly called with gc.collect(); Python never automatically frees memory, requiring developers to manually trigger cleanup when needed\n\nE) Python's GC works like Java: it runs periodically in a separate thread and deletes objects it hasn't seen referenced recently, but there's no guarantee when deletion occurs\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 37: Enumerate Function Behavior\n\n**Theory:** enumerate() returns an iterator that yields pairs of (index, value) from an iterable.\n\nHow does enumerate() work internally, and what happens if you modify the iterable while iterating?\n\nA) enumerate() pre-computes all index-value pairs and stores them in memory; modifying the original iterable has no effect because enumerate uses a cached copy\n\nB) enumerate() is an iterator that yields pairs on-demand; modifying the iterable during iteration leads to undefined behavior, similar to modifying a list while iterating over it\n\nC) enumerate() only works with lists; for other iterables, it raises TypeError, and the modification question doesn't apply because enumerate requires immutable sequences\n\nD) enumerate() automatically creates a snapshot when called, so modifications to the original iterable are ignored; it's safe to modify during enumeration because a copy is used\n\nE) Modifying during enumeration is explicitly supported; enumerate() detects changes and updates its internal index accordingly, keeping enumeration synchronized with modifications\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 38: Zip Function Behavior\n\n**Theory:** zip() takes multiple iterables and returns an iterator that aggregates elements from each iterable.\n\nWhat happens when zip() receives iterables of different lengths, and how does it handle this situation?\n\nA) zip() raises ValueError if iterables have different lengths; all iterables must have the same length, or Python cannot determine how to pair elements\n\nB) zip() stops when the shortest iterable is exhausted, producing pairs only up to the length of the shortest input; remaining elements in longer iterables are ignored\n\nC) zip() pads shorter iterables with None values to match the longest iterable, ensuring all elements from all inputs are included in the output\n\nD) The behavior depends on Python version: Python 2 raises ValueError, but Python 3 automatically pads with None, making version handling important\n\nE) zip() creates pairs for all possible combinations when lengths differ; if one iterable has 3 elements and another has 5, zip produces 15 pairs (3Ã—5 Cartesian product)\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 39: Name Mangling in Classes\n\n**Theory:** Python uses name mangling for attributes starting with double underscores (but not ending with them) to provide a weak form of privacy.\n\nWhat is name mangling, and what problem does it solve in Python classes?\n\nA) Name mangling makes attributes completely private and inaccessible from outside the class; double-underscore attributes can only be accessed from within the same class definition\n\nB) Name mangling rewrites attribute names (__attr becomes _Class__attr) to avoid naming conflicts in inheritance hierarchies; it provides name collision protection, not true privacy\n\nC) Name mangling is a syntax error in modern Python; double underscores in attribute names raise SyntaxError because this feature was removed in Python 3.0\n\nD) Name mangling only works for method names, not attributes; __method becomes _Class__method, but __attribute remains unchanged and accessible normally\n\nE) Python doesn't do name mangling; the double-underscore prefix is just a naming convention that developers use, but Python treats it like any other attribute name\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 40: List vs Tuple Use Cases\n\n**Theory:** Lists are mutable sequences; tuples are immutable sequences. Choosing between them affects both functionality and code semantics.\n\nWhen should you use a tuple instead of a list, and what are the semantic implications of this choice?\n\nA) Tuples should always be preferred because they use less memory and are faster; lists are only needed when you specifically require mutation, which is rarely necessary\n\nB) Use tuples for fixed collections that represent a single conceptual item (like coordinates, database records) or when immutability provides safety; use lists for collections that change\n\nC) The choice is purely stylistic; tuples and lists are functionally identical except for syntax, and the decision should be based on team coding style, not technical requirements\n\nD) Tuples are deprecated in Python 3; they're only kept for backward compatibility with Python 2, and all new code should use lists exclusively\n\nE) Use lists for homogeneous data (all same type) and tuples for heterogeneous data (mixed types); this type-based distinction is more important than mutability\n\n\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Quiz\n",
    "\n",
    "Congratulations on completing all 40 hard theory questions!\n",
    "\n",
    "These questions tested your understanding of:\n",
    "- Python internals and implementation details\n",
    "- Memory management and object behavior\n",
    "- Advanced language features and edge cases\n",
    "- Design decisions and their trade-offs\n",
    "- Subtle behaviors that distinguish experts from beginners\n",
    "\n",
    "**Review the correct answers and explanations to deepen your Python knowledge!**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}